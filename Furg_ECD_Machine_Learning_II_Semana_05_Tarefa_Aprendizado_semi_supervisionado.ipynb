{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Furg - ECD - Machine Learning II - Semana 05 - Tarefa: Aprendizado semi-supervisionado",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcpiscator/2T2021/blob/main/Furg_ECD_Machine_Learning_II_Semana_05_Tarefa_Aprendizado_semi_supervisionado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eMdEdKCZVYZ"
      },
      "source": [
        "# Curso de Especialização em Ciência de Dados - FURG\n",
        "## Machine Learning II - Tarefa: Aprendizado semi-supervisionado\n",
        "### Prof. Marcelo Malheiros\n",
        "\n",
        "Parte do código adaptada de Aurélien Geron (licença Apache-2.0)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVYz5MZxun3t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzyICs3xZVYh"
      },
      "source": [
        "Esta tarefa é para você **observar** e **analisar** este processo de Machine Learning.\n",
        "\n",
        "Adicionalmente, sugere-se que você também experimente com os dados e com os algoritmos, fazendo algumas das modificações indicadas em várias partes deste _notebook_.\n",
        "\n",
        "Note que não é preciso escrever mais código, apenas modificar o código já fornecido.\n",
        "\n",
        "Um questionário _online_ dentro da disciplina no AVA será disponibilizado para coletar sua análise. Este questionário será também uma das tarefas avaliativas desta disciplina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ17LZosZVYj"
      },
      "source": [
        "# Problema\n",
        "\n",
        "O problema aqui descrito é uma **tarefa de classificação semi-supervisionada**. Com base na identificação de apenas alguns dígitos manuscritos, experimentaremos estratégias para **rotular automaticamente** todo o restante de um conjunto de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfnnMWTYZVYk"
      },
      "source": [
        "# Inicialização\n",
        "\n",
        "Aqui importamos as bibliotecas fundamentais de Python para este _notebook_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T133GVCLZVYm"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLDWDyGoZVYo"
      },
      "source": [
        "# Conjunto de dados\n",
        "\n",
        "Vamos trabalhar com o _dataset_ embutido na biblioteca Scikit-Learn chamado `digits`, que contém 1797 imagens em tons de cinza representando os dígitos manuscritos de 0 a 9.\n",
        "\n",
        "Cada instância corresponde a uma matriz de 8 × 8 pixels, ou seja, contém 64 atributos. Adicionalmente, também usaremos os rótulos fornecidos por este _dataset_ como teste da qualidade do nosso processo de rotulagem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUWTIM72ZVYp"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "X_digits, y_digits = load_digits(return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqs9XHYFZVYp"
      },
      "source": [
        "Vamos dividir os dados em 75% como conjunto de treinamento e 25% como conjunto de teste.\n",
        "\n",
        "Para os dados de treino, iremos trabalhar apenas com os atributos. Os rótulos de treino serão usados uma única vez, para definir nossa acurácia de referência.\n",
        "\n",
        "Os dados de teste (atributos e rótulos) serão usados para medir a acurácia dos classificadores construídos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKiB2z23ZVYq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# separação dos dados\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X_digits, y_digits, random_state=42, train_size=0.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGhClcLxZVYs"
      },
      "source": [
        "print('atributos de treino', X_treino.shape)\n",
        "print('rótulos de treino  ', y_treino.shape)\n",
        "print('atributos de teste ', X_teste.shape)\n",
        "print('rótulos de teste   ', y_teste.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKiJfPLVZVYv"
      },
      "source": [
        "# Acurácia de referência\n",
        "\n",
        "Usaremos os dados completos de treino e teste para medir a **acurácia** de referência para este _dataset_, usando para isso uma tarefa tradicional de classificação supervisionada com o algoritmo `LogisticRegression`. Lembrando, apesar do nome este algoritmo pode funcionar como um **classificador multiclasse**.\n",
        "\n",
        "Outro classificador poderia ser usado. Por exemplo, o `RandomForestClassifier`, que teria uma acurácia semelhante à obtida a seguir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJy9Fs_UZVYv"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# criação do classificador\n",
        "log_reg = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=5000, random_state=42)\n",
        "\n",
        "# treinamento com os dados completos de treino\n",
        "log_reg.fit(X_treino, y_treino)\n",
        "\n",
        "# acurácia média com base nos dados de teste\n",
        "log_reg.score(X_teste, y_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7CYGyiBZVYw"
      },
      "source": [
        "Esta é a nossa linha de base: 96,9% de acurácia.\n",
        "\n",
        "Vamos ver se podemos chegar próximo desse percentual usando diversas estratégias de classificação semi-supervisionada..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAKspyTWZVYx"
      },
      "source": [
        "# Rotulagem manual de algumas instâncias\n",
        "\n",
        "A ideia da classificação semi-supervisionada é dispor de apenas algumas poucas instâncias rotuladas, o que tipicamente é feito manualmente.\n",
        "\n",
        "De um total de 1347 instâncias de treino, vamos primeiro experimentar treinar o mesmo tipo de classificador com apenas 50 instâncias quaisquer. Por simplicidade, vamos selecionar os 50 primeiros dígitos de treino e definir explicitamente seus rótulos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waDIVC0HZVYx"
      },
      "source": [
        "n_primeiras = 50\n",
        "\n",
        "X_treino_primeiras = X_treino[:n_primeiras]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en1FPdt8ZVYx"
      },
      "source": [
        "# função auxiliar para mostrar grupos de 10 dígitos\n",
        "def exibe_dígitos(X):\n",
        "    plt.figure(figsize=(6, 3))\n",
        "    for index, X_digit in enumerate(X):\n",
        "        plt.subplot(X.shape[0] // 10, 10, index + 1)\n",
        "        plt.imshow(X_digit.reshape(8, 8), cmap='binary', interpolation='none')\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsEd2edCZVYy"
      },
      "source": [
        "# vamos exibir os primeiros 50 dígitos\n",
        "exibe_dígitos(X_treino_primeiras)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_87aR_AXZVYz"
      },
      "source": [
        "# Aqui definimos manualmente os rótulos de cada uma destas instâncias\n",
        "y_treino_primeiras = np.array([5, 2, 0, 8, 7, 3, 7, 0, 2, 2, \\\n",
        "                               3, 5, 8, 7, 3, 6, 5, 9, 9, 2, \\\n",
        "                               5, 6, 3, 0, 7, 1, 1, 9, 6, 1, \\\n",
        "                               1, 0, 0, 2, 9, 3, 9, 9, 3, 7, \\\n",
        "                               7, 1, 3, 5, 4, 6, 1, 2, 1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akH1h6N1ZVYz"
      },
      "source": [
        "# vamos criar um novo classificador, apenas para estas 50 instâncias\n",
        "log_reg = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=5000, random_state=42)\n",
        "log_reg.fit(X_treino_primeiras, y_treino_primeiras)\n",
        "log_reg.score(X_teste, y_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbfEOLRTZVY0"
      },
      "source": [
        "A acurácia ficou bem abaixo do valor de referência de 96,9%, mas isso já era esperado. Primeiro porque estamos treinando apenas com um número bem pequeno de instâncias (50). Segundo, porque estas instâncias provavelmente não foram as mais adequadas de se rotular.\n",
        "\n",
        "Veremos em seguida como aprimorar este processo semi-supervisionado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlf1KMt5ZVY0"
      },
      "source": [
        "# Usando clusterização no Aprendizado Semi-supervisionado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL1bcsjnZVY0"
      },
      "source": [
        "Quando temos muitas instâncias não rotuladas e poucas instâncias rotuladas, podemos usar a clusterização como forma de ganhar mais conhecimento sobre os dados. E por conseguinte, rotular instâncias mais significativas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNsfDv4PZVY2"
      },
      "source": [
        "## Clusterização\n",
        "\n",
        "Primeiro, vamos agrupar o conjunto de treinamento em 50 _clusters_, usando o algoritmo `KMeans`. Esse número de _clusters_ é arbitrário, mas poderíamos usar uma análise de curva de inércia ou de coeficiente de silhueta para procurar um número mais adequado a estes dados.\n",
        "\n",
        "É importante notar que mesmo que saibamos que as imagens dos dígitos representam apenas 10 classes, a escolha do número de _clusters_ não precisa estar atrelado a este valor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6tg6XgOZVY2"
      },
      "source": [
        "n_clusters = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjNwbM7RZVY2"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# criação do clusterizador\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "\n",
        "# treinamento com os dados completos\n",
        "kmeans.fit(X_treino);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5gGnEzyZVY2"
      },
      "source": [
        "Após o treinamento, o modelo identificou 50 _clusters_. Cada um deles tem um **centróide** ao qual são associadas as instâncias mais próximas.\n",
        "\n",
        "As informações que nos interessam agora são as distâncias de cada instância a cada centróide, dadas pela função `.transform()` e também em que _cluster_ está cada instância, informado pela função `.predict()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttJtGDbWZVY2"
      },
      "source": [
        "# distâncias para cada um dos centróides\n",
        "X_treino_todas_distâncias = kmeans.transform(X_treino)\n",
        "\n",
        "# associação de instâncias ao seu cluster\n",
        "X_treino_clusters = kmeans.predict(X_treino)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a9O7Dg3ZVY3"
      },
      "source": [
        "Como apenas nos interessa a distância de uma instância ao seu centróide (e não a todos), podemos consolidar os dados anteriores em uma só matriz: cada linha é uma instância e a única coluna corresponde à distância ao centróide associado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTclI6QSZVY3"
      },
      "source": [
        "X_treino_distâncias = X_treino_todas_distâncias[np.arange(len(X_treino)), X_treino_clusters]\n",
        "X_treino_distâncias.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZaPKk7bZVY5"
      },
      "source": [
        "## Seleção das instâncias mais representativas\n",
        "\n",
        "Agora, para cada conjunto de instâncias associado a um _cluster_, vamos selecionar a instância com menor distância do centróide.\n",
        "\n",
        "Isso significa que estaremos identificando instâncias bem centrais em cada _cluster_, e portanto representativas dos seus grupos.\n",
        "\n",
        "**Experimentação:** Teste selecionar duas instâncias representativas para cada _cluster_, alterando a variável `n_representativas` abaixo. É preciso também ajustar os rótulos para as 100 imagens representativas que serão exibidas depois."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnaOguVNZVY5"
      },
      "source": [
        "n_representativas = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9IRXUSmZVY5"
      },
      "source": [
        "# função auxiliar\n",
        "def índices_dos_menores(a, n):\n",
        "    if np.ma.isMaskedArray(a):\n",
        "        n = min(n, a.count())\n",
        "    idxs = np.argsort(a)\n",
        "    return idxs[:n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGiGkzIvZVY6"
      },
      "source": [
        "índices = []\n",
        "\n",
        "# para cada cluster\n",
        "for c in range(n_clusters):\n",
        "    # cria um 'masked array' mantendo visíveis apenas as instâncias do cluster 'c'\n",
        "    ma = np.ma.masked_where(X_treino_clusters != c, X_treino_distâncias)\n",
        "\n",
        "    # obtém o índice da instância com menor distância ao centro deste cluster\n",
        "    índices += list(índices_dos_menores(ma, n_representativas))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y1OaocbZVY6"
      },
      "source": [
        "print(índices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9V_PemOZVY7"
      },
      "source": [
        "Agora vamos usar estes 50 índices para copiar os atributos para um novo _dataset_ de treino para o classificador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPweCYxZZVY7"
      },
      "source": [
        "# novo dataset\n",
        "X_treino_representativas = X_treino[índices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQujy9lzZVY7"
      },
      "source": [
        "Então vamos plotar essas instâncias representativas e rotulá-las manualmente a seguir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I8KH3F4ZVY8"
      },
      "source": [
        "exibe_dígitos(X_treino_representativas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnYvq58kZVY8"
      },
      "source": [
        "y_treino_representativas = [0, 1, 3, 2, 7, 6, 4, 6, 9, 5, \\\n",
        "                            1, 2, 9, 5, 2, 7, 8, 1, 8, 6, \\\n",
        "                            3, 1, 5, 4, 5, 4, 0, 3, 2, 6, \\\n",
        "                            1, 7, 7, 9, 1, 8, 6, 5, 4, 8, \\\n",
        "                            5, 3, 3, 6, 7, 9, 7, 8, 4, 9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDF3zGXaZVY9"
      },
      "source": [
        "## Treinamento de um novo classificador\n",
        "\n",
        "Temos no momento um conjunto de dados com apenas 50 instâncias rotuladas, mas em vez de serem instâncias aleatórias, cada uma delas é uma instância representativa de seu _cluster_.\n",
        "\n",
        "Vamos treinar um novo classificador para verificar se o desempenho ficou melhor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i8d3nx7ZVY9"
      },
      "source": [
        "# vamos criar um novo classificador, para as 50 instâncias representativas\n",
        "log_reg = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=5000, random_state=42)\n",
        "log_reg.fit(X_treino_representativas, y_treino_representativas)\n",
        "log_reg.score(X_teste, y_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkFucQQ-ZVY9"
      },
      "source": [
        "O aumento da acurácia é definitivamente melhor, pulando de 83,4% para 92,2%. Note que estamos mais próximos da acurária de referência de 96,9%, mesmo que usando apenas 50 instâncias.\n",
        "\n",
        "Como costuma ser caro e trabalhoso rotular as instâncias, especialmente quando precisa ser feito manualmente por especialistas, uma boa ideia é fazer com que estes rotulem instâncias representativas em vez de apenas instâncias aleatórias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXymH8SYZVY-"
      },
      "source": [
        "## Propagação de rótulos para todo o _cluster_\n",
        "\n",
        "Uma estratégia adicional e que pode ser interessante é propagar os rótulos das instâncias representativas (definidas anteriormente) para todas as outras instâncias do mesmo cluster. Assim poderíamos usar o conjunto de treino completo, e não apenas as 50 instâncias representativas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeoGdKdqZVY-"
      },
      "source": [
        "# matriz-coluna para receber os rótulos propagados\n",
        "y_treino_propagado = np.empty(len(X_treino), dtype=int)\n",
        "\n",
        "# para cada cluster\n",
        "for c in range(n_clusters):\n",
        "    # defina os rótulos das instâncias deste cluster com base no rótulo da sua instância representativa\n",
        "    y_treino_propagado[X_treino_clusters == c] = y_treino_representativas[c * n_representativas]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8BXWmVJZVY-"
      },
      "source": [
        "# vamos criar um novo classificador, para todas as instâncias com rótulos propagados\n",
        "log_reg = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=5000, random_state=42)\n",
        "log_reg.fit(X_treino, y_treino_propagado)\n",
        "log_reg.score(X_teste, y_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yVkTRjwZVY-"
      },
      "source": [
        "De fato, percebe-se um pequeno ganho. E com pouco esforço."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajng5G5KZVY_"
      },
      "source": [
        "## Propagação parcial de rótulos\n",
        "\n",
        "Uma estratégia que seria teoricamente melhor é propagar os rótulos apenas para um percentual das instâncias mais próximas a cada centróide.\n",
        "\n",
        "A lógica é que as instâncias mais distantes podem ser _outliers), e neste caso poderiam ser deixadas de fora. Assim temos um conjunto de treino com bem mais que 50 instâncias, mas sem usar instâncias potencialmente problemáticas.\n",
        "\n",
        "Vamos então definir a propagação para as 75% das instâncias mais próximas, para cada _cluster_.\n",
        "\n",
        "**Experimentação:** Teste modificar o percentual de propagação para valores mais baixos, como por exemplo 15% ou 55%. Note que se definirmos 100% teremos exatamente a situação anterior de propagação para todas as instâncias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boMt_V8VZVY_"
      },
      "source": [
        "# critério de uso\n",
        "percentual = 75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7TH_93cZVY_"
      },
      "source": [
        "# vetor que irá conter apenas as distâncias dentro do percentual\n",
        "distâncias = X_treino_distâncias.copy()\n",
        "\n",
        "# para cada cluster\n",
        "for c in range(n_clusters):\n",
        "    # máscara de booleanos de instâncias no cluster 'c'\n",
        "    no_cluster = (X_treino_clusters == c)\n",
        "    \n",
        "    # apenas distâncias das instâncias neste cluster\n",
        "    cluster_dist = distâncias[no_cluster]\n",
        "    \n",
        "    # distância de corte\n",
        "    corte = np.percentile(cluster_dist, percentual)\n",
        "    \n",
        "    # máscara de corte (para mais distantes)\n",
        "    acima_do_corte = (distâncias > corte)\n",
        "    \n",
        "    # remove distâncias das instâncias que não interessam\n",
        "    distâncias[no_cluster & acima_do_corte] = -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZwbo3KUZVZB"
      },
      "source": [
        "parcialmente_propagado = (distâncias != -1)\n",
        "X_treino_parcial = X_treino[parcialmente_propagado]\n",
        "y_treino_parcial = y_treino_propagado[parcialmente_propagado]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXLpy1rKZVZB"
      },
      "source": [
        "print('novo treino atributos', X_treino_parcial.shape)\n",
        "print('novo treino rótulos  ', y_treino_parcial.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwCYXAdsZVZC"
      },
      "source": [
        "# vamos criar um novo classificador, apenas para as instâncias com rótulos propagados\n",
        "log_reg = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=5000, random_state=42)\n",
        "log_reg.fit(X_treino_parcial, y_treino_parcial)\n",
        "log_reg.score(X_teste, y_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yplY5fdZVZC"
      },
      "source": [
        "O resultado em geral fica um pouco melhor ao se usar propagação parcial, mas depende do percentual dos valores mantidos.\n",
        "\n",
        "Com apenas 50 instâncias rotuladas (apenas 5 exemplos por classe em média) e propagando os demais rótulos, obtivemos  um desempenho que se aproxima do desempenho da regressão logística no _dataset_ totalmente rotulado (que foi de 96,9%).\n",
        "\n",
        "A explicação para o bom desempenho é que os rótulos propagados são realmente muito bons. Podemos comparar diretamente a acurácia deles em relação aos rótulos do conjunto de dados original:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY_gORdWZVZD"
      },
      "source": [
        "# ATENÇÃO: esta é acurácia apenas dos rótulos propagados (e não do classificador treinado)\n",
        "np.mean(y_treino_parcial == y_treino[parcialmente_propagado])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3xXLODJZVZD"
      },
      "source": [
        "**Experimentação avançada:** Teste valores menores (por exemplo, 10) e maiores (por exemplo, 80) para o número de _clusters_ definido por `n_clusters` (na seção **Clusterização**). Então execute novamente os demais trechos do notebook, notando o efeito na acurácia.\n",
        "\n",
        "O número de _clusters_ precisa ser múltiplo de 10 para a visualização dos dígitos funcione adequadamente. Note que as instâncias manualmente rotuladas (na seção **Seleção das instâncias mais representativas**) também terão que ser ajustadas de acordo."
      ]
    }
  ]
}