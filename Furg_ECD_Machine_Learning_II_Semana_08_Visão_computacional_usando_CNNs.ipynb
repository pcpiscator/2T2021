{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Furg - ECD - Machine Learning II - Semana 08 - Visão computacional usando CNNs",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcpiscator/2T2021/blob/main/Furg_ECD_Machine_Learning_II_Semana_08_Vis%C3%A3o_computacional_usando_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJFLoc3mwrCz"
      },
      "source": [
        "# Curso de Especialização em Ciência de Dados - FURG\n",
        "## Machine Learning II - Visão computacional usando CNNs\n",
        "### Prof. Marcelo Malheiros\n",
        "\n",
        "Parte do código adaptada de Aurélien Geron (licença Apache-2.0)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHIIL4q6etY4"
      },
      "source": [
        "# **Atenção**\n",
        "\n",
        "Dada a complexidade das redes utilizadas, é recomendável executar este _notebook_ de forma que a biblioteca TensorFlow utilize uma GPU para seu processamento. Dentro do Colaboratory é preciso mudar o tipo de ambiente _runtime_ deste notebook. Então selecione a opção:\n",
        "\n",
        "`Runtime > Change runtime type > Hardware accelerator: GPU`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kihGyYyUwrC_"
      },
      "source": [
        "# Inicialização\n",
        "\n",
        "Aqui importamos as bibliotecas fundamentais de Python para este _notebook_:\n",
        "\n",
        "- NumPy: suporte a vetores, matrizes e operações de Álgebra Linear\n",
        "- Matplotlib: biblioteca de visualização de dados\n",
        "- Pandas: pacote estatístico e de manipulação de DataFrames\n",
        "- Scikit-Learn: biblioteca com algoritmos de Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ZZtbETwrDB"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6kG2Du_wrDE"
      },
      "source": [
        "Este _notebook_, em particular, utiliza a biblioteca Keras para definir e treinar redes neurais. Aqui utilizamos a versão **integrada** de Keras, que já vem como parte da biblioteca mais geral TensorFlow. Ambas já fazem parte do ambiente Colaboratory.\n",
        "\n",
        "Para quem utiliza o ambiente Anaconda, é preciso primeiro instalar o pacote `tensorflow`. Isso pode ser feito com o seguinte comando:\n",
        "\n",
        "    conda install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyyGcWDiwrDF"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print('tensorflow:      versão', tf.__version__)\n",
        "print('keras integrada: versão', keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Dcp34BwrDJ"
      },
      "source": [
        "Este _notebook_ também utiliza a biblioteca `pydot` e a ferramenta Graphviz para visualizar as redes neurais. Ambos já fazem parte do ambiente Colaboratory.\n",
        "\n",
        "Para quem utiliza o ambiente Anaconda, é preciso primeiro instalar os pacotes `pydot` e `graphviz`. Isso pode ser feito com o seguinte comando:\n",
        "\n",
        "    conda install pydot graphviz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mHPH888wrDL"
      },
      "source": [
        "import pydot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xvAaM2aoxcq"
      },
      "source": [
        "# Redes neurais convolucionais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpxZ2b47etZJ"
      },
      "source": [
        "## Filtros\n",
        "\n",
        "Aqui mostramos um exemplo simples da operação de convolução, definindo dois filtros simples e aplicando os mesmos a duas imagens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0kKlCm_etZJ"
      },
      "source": [
        "from sklearn.datasets import load_sample_image\n",
        "\n",
        "# carrega duas imagens de exemplo da biblioteca Scikit-Learn\n",
        "china = load_sample_image('china.jpg') / 255\n",
        "flower = load_sample_image('flower.jpg') / 255\n",
        "\n",
        "# as imagens precisam estar agrupadas em um conjunto\n",
        "images = np.array([china, flower])\n",
        "batch_size, height, width, channels = images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oti1BkaJ7ARe"
      },
      "source": [
        "# definição de dois filtros simples\n",
        "filters = np.zeros(shape=(7, 7, channels, 2), dtype=np.float32)\n",
        "filters[:, 3, :, 0] = 1  # linha vertical\n",
        "filters[3, :, :, 1] = 1  # linha horizontal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb9P4DgZ7CzH"
      },
      "source": [
        "# operação de convolução sobre as duas imagens, usando os dois filtros\n",
        "outputs = tf.nn.conv2d(images, filters, strides=1, padding='SAME')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbMIOG2etZI"
      },
      "source": [
        "# funções auxiliares\n",
        "\n",
        "def plot_image(image, axis='off'):\n",
        "    plt.imshow(image, cmap='gray', interpolation='nearest')\n",
        "    plt.axis(axis)\n",
        "\n",
        "def plot_color_image(image, axis='off'):\n",
        "    plt.imshow(image, interpolation='nearest')\n",
        "    plt.axis(axis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yls2rnL2etZM"
      },
      "source": [
        "# exibição dos resultados\n",
        "plt.figure(figsize=(14, 4), tight_layout=True)\n",
        "for image_index in (0, 1):\n",
        "    for feature_map_index in (0, 1):\n",
        "        plt.subplot(1, 4, image_index * 2 + feature_map_index + 1)\n",
        "        plot_image(outputs[image_index, :, :, feature_map_index])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pil9nPuetZN"
      },
      "source": [
        "# exibição de detalhes dos resultados\n",
        "\n",
        "# função auxiliar\n",
        "def crop(images):\n",
        "    return images[150:220, 130:250]\n",
        "\n",
        "plt.figure(figsize=(14, 4), tight_layout=True)\n",
        "plt.subplot(1, 3, 1)\n",
        "plot_image(crop(images[0, :, :, 0]))\n",
        "image_index = 0\n",
        "for feature_map_index in (0, 1):\n",
        "    plt.subplot(1, 3, image_index * 2 + feature_map_index + 2)\n",
        "    plot_image(crop(outputs[image_index, :, :, feature_map_index]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sbPYWnLetZP"
      },
      "source": [
        "# exibição dos filtros como imagens\n",
        "plt.figure(figsize=(6, 3), tight_layout=True)\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_image(filters[:, :, 0, 0], 'on')\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_image(filters[:, :, 0, 1], 'on')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiuSc0xtetZQ"
      },
      "source": [
        "## Camadas de convolução\n",
        "\n",
        "Aqui vamos ilustrar a criação e funcionamento de uma camada de convolução bidimensional, especificada pela função `Conv2D` da biblioteca Keras.\n",
        "\n",
        "Vamos criar uma camada com 2 filtros (`filters=2`), cada um sendo um quadrado de lado 7 (`kernel_size=7`). O espaçamento entre filtros é 1 _pixel_ (`strides=1`), ou seja, são aplicados a conjuntos contiguos de _pixels_.\n",
        "\n",
        "O preenchimento das bordas com valores zero é dado pelo parâmetro `padding='SAME'`, enquanto a função de ativação a ser aplicada é especificada por `activation='relu'`.\n",
        "\n",
        "Finalmente, também precisamos especificar o formato da entrada com `input_shape=outputs.shape`, que precisa ser compatível com dados a serem passados a esta camada.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1gWm8OFwrDI"
      },
      "source": [
        "# inicialização das sementes aleatórias para repetibilidade\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlOXRylCetZQ"
      },
      "source": [
        "# criação da camada\n",
        "conv = keras.layers.Conv2D(filters=2, kernel_size=7, strides=1,\n",
        "                           padding='SAME', activation='relu',\n",
        "                           input_shape=images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPazma9AetZR"
      },
      "source": [
        "# aplicação para as duas imagens anteriores\n",
        "conv_outputs = conv(images)\n",
        "conv_outputs.shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_gA3S91etZS"
      },
      "source": [
        "A saída é uma matriz de quatro dimensões (chamada de **tensor** no contexto da biblioteca TensorFlow). As dimensões são: tamanho do lote, altura, largura e canais.\n",
        "\n",
        "A primeira dimensão (tamanho do lote) é 2, pois há 2 imagens de entrada. As próximas duas dimensões são a altura e largura dos mapas de _features_ da saída: uma vez que `padding='SAME'` e `strides=1`, os mapas de _features_ de saída têm a mesma altura e largura das imagens de entrada (neste caso, 427 por 640 _pixels_). Por último, esta camada convolucional tem 2 filtros, então a última dimensão é 2: há 2 mapas de _features_ de saída por imagem de entrada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_OqdrK6etZT"
      },
      "source": [
        "Como os filtros são inicializados aleatoriamente, eles inicialmente detectam padrões aleatórios. Abaixo vamos exibir os mapas de _features_ de cada imagem:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7skL1XT-etZT"
      },
      "source": [
        "# exibição dos resultados\n",
        "plt.figure(figsize=(14, 4), tight_layout=True)\n",
        "for image_index in (0, 1):\n",
        "    for feature_map_index in (0, 1):\n",
        "        plt.subplot(1, 4, image_index * 2 + feature_map_index + 1)\n",
        "        plot_image(crop(conv_outputs[image_index, :, :, feature_map_index]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hPxOltfetZU"
      },
      "source": [
        "Embora os filtros tenham sido inicializados aleatoriamente, o segundo filtro age como um **detector de borda**.\n",
        "\n",
        "Filtros inicializados aleatoriamente geralmente agem dessa maneira, o que é uma muito útil, pois detectar bordas é fundamental no processamento de imagens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRw8QaSNetZZ"
      },
      "source": [
        "## Camadas de agrupamento\n",
        "\n",
        "Aqui vamos demonstrar manualmente o funcionamento de dois tipos de camadas de agrupamento (_pooling layers_).\n",
        "\n",
        "O tipo mais comum é o _max pooling_, em que apenas o maior elemento de um grupo de entradas é mantido.\n",
        "\n",
        "Outro tipo, menos comum mas ainda assim útil em alguns contextos, é o _average pooling_. Como diz seu nome, ele retorna a média aritmética dos valores.\n",
        "\n",
        "No dois casos, como a camada de agrupamento condensa _pixels_ de sua entrada, a saída é sempre uma imagem de resolução menor. Neste caso, com uma redução pela metade, dada pelo parâmetro `pool_size=2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWkRJQ8yHYBe"
      },
      "source": [
        "import matplotlib as mpl\n",
        "\n",
        "# função auxiliar de visualização\n",
        "def plot_max_avg(image, max_output, avg_output):\n",
        "    fig = plt.figure(figsize=(12, 8))\n",
        "    gs = mpl.gridspec.GridSpec(nrows=1, ncols=3, width_ratios=[2, 1, 1])\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    ax1.set_title('entrada', fontsize=14)\n",
        "    ax1.imshow(image)\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    ax2.set_title('max', fontsize=14)\n",
        "    ax2.imshow(max_output)\n",
        "    ax3 = fig.add_subplot(gs[0, 2])\n",
        "    ax3.set_title('average', fontsize=14)\n",
        "    ax3.imshow(avg_output)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZfI_C4sH36M"
      },
      "source": [
        "# aplicação nos recortes das imagens\n",
        "cropped_images = np.array([crop(image) for image in images], dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXW_FIHxetZa"
      },
      "source": [
        "# camada de max pooling\n",
        "max_pool = keras.layers.MaxPool2D(pool_size=2)\n",
        "max_output = max_pool(cropped_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7rSwNysetZe"
      },
      "source": [
        "# camada de average pooling\n",
        "avg_pool = keras.layers.AvgPool2D(pool_size=2)\n",
        "avg_output = avg_pool(cropped_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRumVgA1etZe"
      },
      "source": [
        "# visualização\n",
        "plot_max_avg(cropped_images[0], max_output[0], avg_output[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NasGaLStRa_j"
      },
      "source": [
        "# Classificador de imagens usando uma CNN\n",
        "\n",
        "Aqui vamos construir uma classificador usando uma arquitetura tradicional de CNN para usar no _dataset_ **Fashion MNIST**, com imagens reduzidas de roupas.\n",
        "\n",
        "Vamos fazer a abordagem usual de construir conjuntos de **treino**, **validação** e de **teste**, medindo ao final a acurácia da predição sobre o conjunto de teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN7LSxFhwrDd"
      },
      "source": [
        "## Conjunto de dados\n",
        "\n",
        "A biblioteca Keras tem várias funções para carregar conjuntos de dados populares em `keras.datasets`. \n",
        "\n",
        "O _dataset_ **Fashion MNIST** já está dividido entre instâncias de treinamento e de teste, mas a seguir iremos dividir o conjunto de treinamento para ter um conjunto de validação. Cada instância é uma imagem em tons de cinza (com valores de 0 a 255) e com resolução 28 por 28 _pixels_.\n",
        "\n",
        "Note que esse _dataset_ foi feito para ser compatível com o conjunto **MNIST** original, tendo a mesma resolução, número de instâncias e número de classes (10), porém sendo mais desafiador de classificar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7YMhTcVwrDd"
      },
      "source": [
        "# importação do dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylbykR5IPHey"
      },
      "source": [
        "print('treinamento completo:', X_train_full.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc3uyneVwrDe"
      },
      "source": [
        "Aqui o conjunto completo de treinamento é quebrado em dois, um de treinamento menor e outro de validação. Também é feita a conversão dos valores inteiros de tons de cinza (de 0 a 255) para um valor real no intervalo de 0 a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKwdz38_wrDe"
      },
      "source": [
        "# separação dos dados de treinamento e validação\n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# adição de mais uma dimensão, para indicar o único canal de cor (tons de cinza)\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_valid = X_valid[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0uAfRRnTDaU"
      },
      "source": [
        "print('treinamento:', X_train.shape)\n",
        "print('validação:   ', X_valid.shape)\n",
        "print('testes:     ', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbganIWOwrDe"
      },
      "source": [
        "Os rótulos são valores inteiros de 0 a 9, guardados nos vetores `y` e que correspondem aos seguintes nomes de classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKNcnyuCwrDf"
      },
      "source": [
        "class_names = ['camiseta', 'calça', 'pulôver', 'vestido', 'casaco',\n",
        "               'sandália', 'camisa', 'tênis', 'bolsa', 'bota']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NcJX-3vwrDf"
      },
      "source": [
        "Abaixo é exibido um mosaico com várias instâncias do conjunto de treino:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FMPUDiXwrDg"
      },
      "source": [
        "# visualização das instâncias\n",
        "n_rows = 4\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index, :, :, 0], cmap='binary')\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_train[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28WQ8r2LmNvr"
      },
      "source": [
        "## Criação da rede neural convolucional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9iGEbYSwrDh"
      },
      "source": [
        "# comando para 'zerar' a biblioteca Keras\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# definição de sementes aleatórias\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvYocEBowrDg"
      },
      "source": [
        "Aqui vamos criar uma rede neural de classificação, usando um modelo (ou arquitetura) do tipo sequencial. O modelo sequencial corresponde ao tipo mais simples de rede neural, onde uma sequência de camadas de neurônios é empilhada uma em cima da outra.\n",
        "\n",
        "- A criação começa com a chamada a `Sequential`, que define o tipo do modelo:\n",
        "\n",
        "        model = keras.models.Sequential()\n",
        "\n",
        "- Então uma camada convolucional do tipo `Conv2D` é adicionada. Ela define 32 filtros, cada um com tamanho 3 por 3. O parâmetro _strides_ é 1 e o preenchimento das bordas é feito com zeros, então a camada abaixo receberá a mesma resolução da imagem que entra nesta camada. A função de ativação é do tipo ReLU. Como esta é a primeira camada, é preciso definir o formato da entrada com `input_shape`:\n",
        "\n",
        "        keras.layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=[28, 28, 1])\n",
        "\n",
        "- A seguir adicionamos mais uma camada convolucional. A única diferença agora é que esta contém 64 filtros, também de tamanho 3 por 3.\n",
        "\n",
        "        keras.layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "\n",
        "- Em seguida, temos uma camada de _max pooling_ que usa um tamanho de pool de 2. Portanto, esta camada divide cada dimensão espacial por um fator de 2.\n",
        "\n",
        "        keras.layers.MaxPool2D(pool_size=2)\n",
        "\n",
        "Para imagens maiores, poderíamos repetir essa estrutura de camadas de convolução e camadas de agrupamento várias vezes, até reduzir significativamente o tamanho da imagem. Assim, o número de repetições é um hiperparâmetro da arquitetura da rede.\n",
        "\n",
        "Observe que o número de filtros tipicamente aumenta à medida em que caminhamos em uma CNN em direção à camada de saída. Isso faz sentido porque o número de detalhes menores de uma imagem costuma ser pequeno (por exemplo, pequenos círculos ou linhas horizontais). Entretanto, existem muitas maneiras diferentes de combiná-los em _features_ de nível superior.\n",
        "\n",
        "Então é uma prática comum **dobrar** o número de filtros a cada camada de convolução. Uma vez que uma camada de agrupamento divide cada dimensão espacial por um fator de 2, podemos dobrar o número de mapas de _features_ na próxima camada sem medo de explodir o número de parâmetros, o uso de memória ou a carga computacional.\n",
        "\n",
        "- A seguir, a sequência de camadas deixa de ser convolucional e passa a ser **completamente conectada**, como nas redes neurais tradicionais. A transição é feita por uma camada simples do tipo `Flatten`, que simplesmente enfileira os neurônios ao longo de uma só dimensão.\n",
        "\n",
        "        keras.layers.Flatten()\n",
        "\n",
        "- Então adicionamos uma camada de _dropout_, com uma taxa de abandono de 25% cada, que ajuda a reduzir o efeito de _overfitting_. Ou seja, pode ser entendida como uma **camada de regularização**:\n",
        "\n",
        "        keras.layers.Dropout(0.25)\n",
        "\n",
        "Uma camada de _dropout_ define aleatoriamente algumas unidades de entrada como 0, segundo uma probabilidade especificada. Isso ocorre somente durante o treinamento, mas não acontece durante a inferência. As entradas mantidas são também ajustadas, de forma que a soma de todas as entradas permaneça a mesma. O uso de _dropout_ tende a desacelerar a convergência, mas geralmente resulta em um modelo muito melhor quando ajustado corretamente.\n",
        "\n",
        "- Então uma segunda camada `Dense` é adicionada, com 128 neurônios e função de ativação também ReLU:\n",
        "\n",
        "        keras.layers.Dense(128, activation='relu')\n",
        "\n",
        "- Uma segunda camada de _dropout_ é colocada, agora com taxa de abandono de 50%:\n",
        "\n",
        "        keras.layers.Dropout(0.5)\n",
        "\n",
        "- Finalmente uma camada de saída é adicionada. Aqui o tipo também é `Dense`, mas a função de ativação é trocada para `softmax` para produzir a saída de classificador (uma vez que as 10 classes são mutuamente exclusivas):\n",
        "\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxMK-h83wrDi"
      },
      "source": [
        "# especificação do modelo\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=[28, 28, 1]),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp3kFJEWwrDj"
      },
      "source": [
        "# resumo legível da arquitetura deste modelo\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIyCevX2wrDk"
      },
      "source": [
        "# figura da arquitetura deste modelo\n",
        "keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxCJwQRDwrDk"
      },
      "source": [
        "## Compilando a rede neural\n",
        "\n",
        "Depois que um modelo é criado, é preciso chamar o método `compile()`, especificando a **função de perda** (aqui, a função `sparse_categorical_crossentropy`) e o **otimizador** a ser usado (`nadam`, adequado para redes convolucionais).\n",
        "\n",
        "Opcionalmente, podemos também pode especificar uma lista de **medidas de desempenho** extras para calcular durante o treinamento e avaliação. Neste caso iremos usar apenas a acurácia com `accuracy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4_ru67lwrDk"
      },
      "source": [
        "# compilação do modelo\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYejRmbuwrDl"
      },
      "source": [
        "## Treinando a rede neural\n",
        "\n",
        "Para treinar o modelo basta chamar o método `fit()`. Três parâmetros são obrigatórios: as _features_ de treinamento, os rótulos de treinamento e o número de épocas.\n",
        "\n",
        "Pode ser passado também um conjunto de validação. A biblioteca Keras medirá a perda e as métricas extras ao final de cada época, o que é muito útil para ver como o modelo realmente funciona: se o desempenho no conjunto de treinamento é muito melhor do que no conjunto de validação, provavelmente está ocorrendo _overfitting_.\n",
        "\n",
        "Como esta rede tem **1.625.866 parâmetros**, é fundamental que este _notebook_ esteja sendo acelerado por uma GPU.\n",
        "\n",
        "No caso do Colaboratory, o tempo de treinamento com apenas 10 épocas seria de **35 minutos** usando uma CPU. Já com uma GPU cai para cerca de **3 minutos**. Note que a opção TPU do Colaboratory provavelmente só está disponível com o serviço pago, e caso escolhida no serviço gratuito funciona tal como uma CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEhRR-8GetZi"
      },
      "source": [
        "# treinamento\n",
        "%time history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZfi_VuYwrDm"
      },
      "source": [
        "# visualização da evolução das métricas ao longo do treinamento\n",
        "pd.DataFrame(history.history).plot(figsize=(12, 6))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4kJtWnEojmx"
      },
      "source": [
        "## Avaliação da precisão da rede neural\n",
        "\n",
        "Uma vez treinada, basta avaliarmos sua precisão usando o conjunto de testes. Como pode ser visto abaixo, a acurácia alcançada é de **92,46%**.\n",
        "\n",
        "É interessante recordar que com um classificador baseado em uma rede neural densa tradicional, com 266.610 neurônios obtivemos uma acurácia de **88,14%**, usando exatamente os mesmos conjuntos de treino, validação e de teste. Naquele momento usamos 25 épocas de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLp2x4mTwrDm"
      },
      "source": [
        "# avaliação usando o conjunto de teste\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO5riTx8etZk"
      },
      "source": [
        "# Usando modelos pré-treinados com a Keras\n",
        "\n",
        "A seguir mostramos um breve exemplo de como podemos utilizar a arquitetura de rede bem mais complexa, a **ResNet50**, para fazer classificação de imagens.\n",
        "\n",
        "A biblioteca Keras não apenas já tem muitas arquiteturas robustas implementadas, como também permite carregar todos os **pesos** de um modelo de alta qualidade já treinado. Aqui vamos carregar os pesos do treinamento para o _dataset_ ImageNet, com 1000 classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxxBZneietZk"
      },
      "source": [
        "# criação do modelo\n",
        "model = keras.applications.resnet50.ResNet50(weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ8vs2YLrt2-"
      },
      "source": [
        "Esse modelo exige que as imagens tenham exatamente a resolução de 224 por 224 _pixels_, então é preciso redimensionar as imagens para este tamanho.\n",
        "\n",
        "Vamos ilustrar três procedimentos simples: escalonamento, preenchimento de espaço adicional e recorte."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hLSyCxRetZk"
      },
      "source": [
        "# escalonamento\n",
        "images_resized = tf.image.resize(images, [224, 224])\n",
        "plot_color_image(images_resized[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3MZxKiGetZl"
      },
      "source": [
        "# preenchimento de espaço adicional\n",
        "images_resized = tf.image.resize_with_pad(images, 224, 224, antialias=True)\n",
        "plot_color_image(images_resized[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVZyxZ3netZl"
      },
      "source": [
        "# recorte\n",
        "images_resized = tf.image.resize_with_crop_or_pad(images, 224, 224)\n",
        "plot_color_image(images_resized[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Twv5WPetZm"
      },
      "source": [
        "# idealmente o recorte deveria selecionar a área mais importante manualmente\n",
        "china_box = [0, 0.03, 1, 0.68]\n",
        "flower_box = [0.19, 0.26, 0.86, 0.7]\n",
        "images_resized = tf.image.crop_and_resize(images, [china_box, flower_box], [0, 1], [224, 224])\n",
        "plot_color_image(images_resized[0])\n",
        "plt.show()\n",
        "plot_color_image(images_resized[1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cohIf8ZetZm"
      },
      "source": [
        "# cálculo das probabilidades do classificador\n",
        "inputs = keras.applications.resnet50.preprocess_input(images_resized * 255)\n",
        "Y_proba = model.predict(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEAINwYwetZn"
      },
      "source": [
        "# probabilidade das classes\n",
        "Y_proba.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq0w_uc3s_7r"
      },
      "source": [
        "# decodificador\n",
        "top_k = keras.applications.resnet50.decode_predictions(Y_proba, top=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRKB3P1WetZn"
      },
      "source": [
        "# exibição das classes com maior probabilidade\n",
        "for image_index in range(len(images)):\n",
        "    print('imagem #{}'.format(image_index))\n",
        "    for class_id, name, y_proba in top_k[image_index]:\n",
        "        print('  {} - {:12s} {:.2f}%'.format(class_id, name, y_proba * 100))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnfuz2xETqu8"
      },
      "source": [
        "# resumo legível da arquitetura ResNet50\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iht9a89ETqlE"
      },
      "source": [
        "# figura da arquitetura ResNet50\n",
        "keras.utils.plot_model(model, 'ResNet50.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}